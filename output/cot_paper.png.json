[
  {
    "type": "Title",
    "element_id": "e965717768402affa35f13db1a0d9488",
    "text": "B All Experimental Results",
    "metadata": {
      "filetype": "image/png",
      "languages": [
        "eng"
      ],
      "page_number": 1,
      "filename": "cot_paper.png",
      "data_source": {
        "url": null,
        "version": null,
        "record_locator": {
          "path": "/Users/marcushausch/Documents/Projects/Unstructured/images/cot_paper.png"
        },
        "date_created": "1724446589.6396303",
        "date_modified": "1724446590.283683",
        "date_processed": "1724528118.6192122",
        "permissions_data": [
          {
            "mode": 33188
          }
        ],
        "filesize_bytes": 1079652
      }
    }
  },
  {
    "type": "NarrativeText",
    "element_id": "9a11c0f0f302370a9b149383b4d5f9a5",
    "text": "This section contains tables for experimental results for varying models and model sizes, on all benchmarks, for standard prompting vs. chain-of-thought prompting.",
    "metadata": {
      "filetype": "image/png",
      "languages": [
        "eng"
      ],
      "page_number": 1,
      "parent_id": "e965717768402affa35f13db1a0d9488",
      "filename": "cot_paper.png",
      "data_source": {
        "url": null,
        "version": null,
        "record_locator": {
          "path": "/Users/marcushausch/Documents/Projects/Unstructured/images/cot_paper.png"
        },
        "date_created": "1724446589.6396303",
        "date_modified": "1724446590.283683",
        "date_processed": "1724528118.6192122",
        "permissions_data": [
          {
            "mode": 33188
          }
        ],
        "filesize_bytes": 1079652
      }
    }
  },
  {
    "type": "NarrativeText",
    "element_id": "83e4905672d8c233e12dac2067d6a87e",
    "text": "For the arithmetic reasoning benchmarks, some chains of thought (along with the equations produced) were correct, except the model performed an arithmetic operation incorrectly. A similar observation was made in Cobbe et al. (2021). Hence, we can further add a Python program as an external calculator (using the Python eval function) to all the equations in the generated chain of thought. \u2018When there are multiple equations in a chain of thought, we propagate the external calculator results from one equation to the following equations via string matching. As shown in Table 1, we see that adding a calculator significantly boosts performance of chain-of-thought prompting on most tasks.",
    "metadata": {
      "filetype": "image/png",
      "languages": [
        "eng"
      ],
      "page_number": 1,
      "parent_id": "e965717768402affa35f13db1a0d9488",
      "filename": "cot_paper.png",
      "data_source": {
        "url": null,
        "version": null,
        "record_locator": {
          "path": "/Users/marcushausch/Documents/Projects/Unstructured/images/cot_paper.png"
        },
        "date_created": "1724446589.6396303",
        "date_modified": "1724446590.283683",
        "date_processed": "1724528118.6192122",
        "permissions_data": [
          {
            "mode": 33188
          }
        ],
        "filesize_bytes": 1079652
      }
    }
  },
  {
    "type": "NarrativeText",
    "element_id": "c484bd7943dc6212d6a4feffb61baf7e",
    "text": "Table 1: Chain of thought prompting outperforms standard prompting for various large language models on five arithmetic reasoning benchmarks. All metrics are accuracy (%). Ext. calc.: post-hoc external calculator for arithmetic computations only. Prior best numbers are from the following. a: Cobbe et al. (2021). b & e: Piet al. (2022), c\u00a2: Lan et al. (2021), d: Pigkos et al. (2021).",
    "metadata": {
      "filetype": "image/png",
      "languages": [
        "eng"
      ],
      "page_number": 1,
      "parent_id": "e965717768402affa35f13db1a0d9488",
      "filename": "cot_paper.png",
      "data_source": {
        "url": null,
        "version": null,
        "record_locator": {
          "path": "/Users/marcushausch/Documents/Projects/Unstructured/images/cot_paper.png"
        },
        "date_created": "1724446589.6396303",
        "date_modified": "1724446590.283683",
        "date_processed": "1724528118.6192122",
        "permissions_data": [
          {
            "mode": 33188
          }
        ],
        "filesize_bytes": 1079652
      }
    }
  },
  {
    "type": "Table",
    "element_id": "41f6659246b1106e177383f94bb3a1d0",
    "text": "Prompting GSMBK SVAMP ASDiv AQuUA MAWPS Prior best (finetuning) 55\u00a2 57.4\u00b0 75.3\u00a2 37.94 88.4\u00a2 UL2 20B Standard 4.1 10.1 16.0 20.5 16.6 4.4 +0.3) 12.5 24 16.9 +0.9) 23.6 (+3.1) 19.1 2.5 Chain of thought +ext. calc 6.9 28.3 343 23.6 427 LaMDA 137B Standard 6.5 29.5 40.1 25.5 432 Chain of thought 14.3 (+1.8) 37.5 +8.0) 46.6 (+6.5) 20.6 (4.9 57.9 +147) +ext. calc 17.8 421 53.4 20.6 69.3 GPT-3 175B Standard 15.6 65.7 70.3 24.8 2.7 (text-davinci-002) Chain of thought 46.9 (+31.3) 68.9 (+3.2) 71.3 +1.0) 35.8 (+11.0) 87.1 (+14.4) +ext. calc 49.6 70.3 71.1 35.8 87.5 Codex Standard 19.7 69.9 74.0 29.5 78.1 (code-davinci-002) Chain of thought 63.1 (+43.4) 76.4 (+6.5) 80.4 (+6.4) 45.3 (+15.8) 92.6 (+13.9) +ext. calc 65.4 71.0 80.0 453 933 PalLM 540B Standard 17.9 69.4 72.1 25.2 79.2 Chain of thought 56.9 +39.00 79.0 (+9.6) 73.9 (+1.8) 35.8 (+10.6) 93.3 (+14.2) +ext. calc 58.6 79.8 72.6 35.8 93.5",
    "metadata": {
      "text_as_html": "<table><thead><tr><th></th><th>Prompting</th><th>GSMBK</th><th>SVAMP</th><th>ASDiv</th><th>AQuUA</th><th>MAWPS</th></tr></thead><tbody><tr><td>Prior best</td><td>(finetuning)</td><td>55\u00a2</td><td>57.4\u00b0</td><td>75.3\u00a2</td><td>37.94</td><td>88.4\u00a2</td></tr><tr><td rowspan=\"3\">UL2 20B</td><td>Standard</td><td>4.1</td><td>10.1</td><td>16.0</td><td>20.5</td><td>16.6</td></tr><tr><td>Chain of thought</td><td>4.4 +0.3)</td><td>12.5 24</td><td>16.9 +0.9)</td><td>23.6 (+3.1)</td><td>19.1 2.5</td></tr><tr><td>+ext. calc</td><td>6.9</td><td>28.3</td><td>343</td><td>23.6</td><td>427</td></tr><tr><td rowspan=\"3\">LaMDA 137B</td><td>Standard</td><td>6.5</td><td>29.5</td><td>40.1</td><td>25.5</td><td>432</td></tr><tr><td>Chain of thought</td><td>14.3 (+1.8)</td><td>37.5 +8.0)</td><td>46.6 (+6.5)</td><td>20.6 (4.9</td><td>57.9 +147)</td></tr><tr><td>+ext. calc</td><td>17.8</td><td>421</td><td>53.4</td><td>20.6</td><td>69.3</td></tr><tr><td>GPT-3 175B</td><td>Standard</td><td>15.6</td><td>65.7</td><td>70.3</td><td>24.8</td><td>2.7</td></tr><tr><td rowspan=\"2\">(text-davinci-002)</td><td>Chain of thought</td><td>46.9 (+31.3)</td><td>68.9 (+3.2)</td><td>71.3 +1.0)</td><td>35.8 (+11.0)</td><td>87.1 (+14.4)</td></tr><tr><td>+ext. calc</td><td>49.6</td><td>70.3</td><td>71.1</td><td>35.8</td><td>87.5</td></tr><tr><td>Codex</td><td>Standard</td><td>19.7</td><td>69.9</td><td>74.0</td><td>29.5</td><td>78.1</td></tr><tr><td rowspan=\"2\">(code-davinci-002)</td><td>Chain of thought</td><td>63.1 (+43.4)</td><td>76.4 (+6.5)</td><td>80.4 (+6.4)</td><td>45.3 (+15.8)</td><td>92.6 (+13.9)</td></tr><tr><td>+ext. calc</td><td>65.4</td><td>71.0</td><td>80.0</td><td>453</td><td>933</td></tr><tr><td rowspan=\"3\">PalLM 540B</td><td>Standard</td><td>17.9</td><td>69.4</td><td>72.1</td><td>25.2</td><td>79.2</td></tr><tr><td>Chain of thought</td><td>56.9 +39.00</td><td>79.0 (+9.6)</td><td>73.9 (+1.8)</td><td>35.8 (+10.6)</td><td>93.3 (+14.2)</td></tr><tr><td>+ext. calc</td><td>58.6</td><td>79.8</td><td>72.6</td><td>35.8</td><td>93.5</td></tr></tbody></table>",
      "filetype": "image/png",
      "languages": [
        "eng"
      ],
      "page_number": 1,
      "parent_id": "e965717768402affa35f13db1a0d9488",
      "filename": "cot_paper.png",
      "data_source": {
        "url": null,
        "version": null,
        "record_locator": {
          "path": "/Users/marcushausch/Documents/Projects/Unstructured/images/cot_paper.png"
        },
        "date_created": "1724446589.6396303",
        "date_modified": "1724446590.283683",
        "date_processed": "1724528118.6192122",
        "permissions_data": [
          {
            "mode": 33188
          }
        ],
        "filesize_bytes": 1079652
      }
    }
  }
]